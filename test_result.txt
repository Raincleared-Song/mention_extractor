1. fewnerd-mention-bert_token, step-24000.pkl
setting: Bert-Token-Classification + no bio
max_epoch: 3
max_epoch_f1: 0.8409215578714693
max_epoch_pre: 0.8291134169302454
max_epoch_rec: 0.8530708985983403
max_step: 24000
max_step_f1: 0.8410309215904295
max_step_pre: 0.8242475809801089
max_step_rec: 0.8585119538332938
test result:
micro_f1 = 0.8387922576807684
precision = 0.8221458800098759
recall = 0.8561266707451491

2. fewnerd-mention_bio-bert_token, epoch-3.pkl
setting: Bert-Token-Classification + bio
max_epoch: 3
max_epoch_f1: 0.841659097789718
max_epoch_pre: 0.8245995649592991
max_epoch_rec: 0.8594394064301609
max_step: 12000
max_step_f1: 0.8411341909713126
max_step_pre: 0.8276838976117097
max_step_rec: 0.8550288540806152
test result:
micro_f1 = 0.83982586842558
precision = 0.8222215599200448
recall = 0.8582005205362085

2.1 fewnerd-mention_bio-bert_token-sche, step-20000.pkl
setting: Bert-Token-Classification + bio + warmup 0
max_epoch: 2
max_epoch_f1: 84.36
max_epoch_pre: 83.16
max_epoch_rec: 85.6
max_step: 20000
max_step_f1: 84.37
max_step_pre: 83.16
max_step_rec: 85.61
test result:
micro_f1 = 84.44
precision = 83.27
recall = 85.63

3. fewnerd-mention-bert_crf, step-14000.pkl
setting: Bert-Crf + no bio
max_epoch: 1
max_epoch_f1: 0.8438748738646127
max_epoch_pre: 0.8266903914589113
max_epoch_rec: 0.8617889530088909
max_step: 14000
max_step_f1: 0.8445797019390444
max_step_pre: 0.8289405787320231
max_step_rec: 0.8608202802966075
test result:
micro_f1 = 0.842780971972744
precision = 0.8265112847913683
recall = 0.8597040616347267

4. fewnerd-mention_bio-bert_crf, epoch-0.pkl
setting: Bert-Crf + bio
max_epoch: 0
max_epoch_f1: 0.845103056434057
max_epoch_pre: 0.826567611240132
max_epoch_rec: 0.8644888705686594
max_step: 8000
max_step_f1: 0.8436425429826382
max_step_pre: 0.8190799689439404
max_step_rec: 0.8697238252265315
test result:
micro_f1 = 0.8441831752458313
precision = 0.8262345862869258
recall = 0.8629288980598241

4.1 fewnerd-mention_bio-bert_crf-sche, epoch-1.pkl
setting: Bert-Crf + bio + warmup 0
max_epoch: 1
max_epoch_f1: 84.74
max_epoch_pre: 82.92
max_epoch_rec: 86.65
max_step: 14000
max_step_f1: 84.69
max_step_pre: 83.23
max_step_rec: 86.19
test result:
micro_f1 = 84.66
precision = 82.87
recall = 86.54

5. fewnerd-mention-bert_bilstm_crf, step-16000.pkl
setting: Bert-BiLSTM-Crf + no bio
max_epoch: 3
max_epoch_f1: 0.841847467100078
max_epoch_pre: 0.8303297584442557
max_epoch_rec: 0.8536892003295851
max_step: 16000
max_step_f1: 0.8438946171955745
max_step_pre: 0.8312739923222907
max_step_rec: 0.8569043693320576
test result:
micro_f1 = 0.842041356861365
precision = 0.828732665910126
recall = 0.8557844855296244

6. fewnerd-mention_bio-bert_bilstm_crf, step-18000.pkl
setting: Bert-BiLSTM-Crf + bio
max_epoch: 3
max_epoch_f1: 0.8444070988183798
max_epoch_pre: 0.8298147521736615
max_epoch_rec: 0.8595218466609935
max_step: 18000
max_step_f1: 0.8456244053521639
max_step_pre: 0.8308405266715401
max_step_rec: 0.8609439406428564
test result:
micro_f1 = 0.8438343280259472
precision = 0.828993046871009
recall = 0.8592167069338277

6.1 fewnerd-mention_bio-bert_bilstm_crf-sche, epoch-2.pkl
setting: Bert-BiLSTM-Crf + bio + warmup 0
max_epoch: 2
max_epoch_f1: 84.71
max_epoch_pre: 83.34
max_epoch_rec: 86.12
max_step: 20000
max_step_f1: 84.71
max_step_pre: 83.73
max_step_rec: 85.71
test result:
micro_f1 = 84.62
precision = 83.23
recall = 86.05

7. fewnerd-type-bert_token, step-22000.pkl
setting: Bert-Token-Classification + no bio (type)
max_epoch: 16
max_epoch_f1: 0.6497617701686487
max_epoch_pre: 0.6399172863560982
max_epoch_rec: 0.6599138814843839
max_step: 22000
max_step_f1: 0.6505699936223194
max_step_pre: 0.6328370361752874
max_step_rec: 0.6693254049619296

official baseline Bert-Token-Classification:
f1 = 0.6713079977196261
precision = 0.6557430368018908
recall = 0.6876298355673814

8. fewnerd-type_bio-bert_token, step-50000.pkl
setting: Bert-Token-Classification + bio (type)
max_epoch: 10
max_epoch_f1: 0.6477055353078454
max_epoch_pre: 0.636264736134062
max_epoch_rec: 0.6595653065407711
max_step: 50000
max_step_f1: 0.6498458819866365
max_step_pre: 0.6366837828797268
max_step_rec: 0.6635636661880945

9. fewnerd-type-bert_token-sche, step-76000.pkl
setting: Bert-Token-Classification + no bio (type) + warmup 0
max_epoch: 9
max_epoch_f1: 0.6633880000801606
max_epoch_pre: 0.6497326203207279
max_epoch_rec: 0.6776296903832936
max_step: 76000
max_step_f1: 0.6644926879836016
max_step_pre: 0.6525589578348879
max_step_rec: 0.6768710272707245
test result:
micro_f1 = 0.6609164311462558
precision = 0.6478634511878986
recall = 0.6745062021423011

10. fewnerd-type-bert_token-sche-seg, step-46000.pkl
setting: Bert-Token-Classification + no bio (type) + warmup 0, no 'X'
max_epoch: 9
max_epoch_f1: 0.6635439025856761
max_epoch_pre: 0.6494855482248175
max_epoch_rec: 0.6782243182282801
max_step: 46000
max_step_f1: 0.6648782294470197
max_step_pre: 0.6495276837924842
max_step_rec: 0.6809719089602869
test result:
micro_f1 = 0.659312455021649
precision = 0.6434359805509903
recall = 0.6759922395821886s

11. fewnerd-type_bio-bert_crf-sche, epoch-8.pkl
setting: Bert-Crf + bio (type) + warmup 0
max_epoch: 8
max_epoch_f1: 0.6705733771152977
max_epoch_pre: 0.6609899412407806
max_epoch_rec: 0.6804387943406438
max_step: 56000
max_step_f1: 0.670497076614807
max_step_pre: 0.6616754512057456
max_step_rec: 0.6795571047773878
test result:
micro_f1 = 0.665168511476422
precision = 0.655559452823505
recall = 0.6750634661822589

12. fewnerd-type-bert_crf-sche, epoch-8.pkl
setting: Bert-Crf + no bio (type) + warmup 0
max_epoch: 8
max_epoch_f1: 0.669827664812484
max_epoch_pre: 0.6620271163357575
max_epoch_rec: 0.6778142300593238
max_step: 82000
max_step_f1: 0.6695050344033033
max_step_pre: 0.6590132676569757
max_step_rec: 0.6803362722984048
test_result:
micro_f1 = 0.6661606979168397
precision = 0.6577150156401781
recall = 0.6748261129800547

13. fewnerd-type-bert_token-std, epoch-4.pkl
setting: Bert-Token-Classification + no bio (type) + warmup 0, no 'X', [CLS], [SEP]
max_epoch: 4
max_epoch_f1: 0.6638155472640577
max_epoch_pre: 0.6488428554644929
max_epoch_rec: 0.6794955915520444
max_step: 82000
max_step_f1: 0.6637507223150305
max_step_pre: 0.6497878692644858
max_step_rec: 0.6783268402705191
test result:
micro_f1 = 0.6602645119443833
precision = 0.6450828468194654
recall = 0.6761779942621746
